# Z-Image-Turbo

> A professional web interface for the Tongyi-MAI Z-Image-Turbo model â€” lightning-fast text-to-image generation with 6B parameters.

![Z-Image-Turbo Interface](assets/projectScreenshot.png)

![Z-Image-Turbo](https://img.shields.io/badge/Model-Z--Image--Turbo-blue) ![License](https://img.shields.io/badge/License-Apache%202.0-green)

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Node.js 16+
- 8GB+ VRAM recommended (or use CPU offload)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Aaryan-Kapoor/z-image-turbo.git
   cd z-image-turbo
   ```

2. **Backend Setup**
   ```bash
   python -m venv venv
   
   # Windows
   .\venv\Scripts\activate
   # Linux/Mac
   source venv/bin/activate
   
   pip install -r requirements.txt
   ```

3. **Frontend Setup**
   ```bash
   cd frontend
   npm install
   ```

### Running the Application

**Terminal 1 - Start Backend:**
```bash
.\venv\Scripts\activate  # or source venv/bin/activate on Linux/Mac
cd backend
python main.py
```

**Terminal 2 - Start Frontend:**
```bash
cd frontend
npm run dev
```

Open **`http://localhost:5173`** in your browser and start generating!

---

## ğŸ”Œ MCP Server (Model Context Protocol)

Z-Image-Turbo now includes an **MCP server** that allows AI assistants and other clients to generate images through the standardized Model Context Protocol.

### Quick Start with MCP

**Install MCP dependencies:**
```bash
cd backend
pip install -r requirements.txt
```

**Run the MCP server:**

For local integration (Claude Desktop, MCP Inspector):
```bash
cd backend
./run_mcp.sh --stdio
```

For HTTP/web clients:
```bash
cd backend
./run_mcp.sh --http --port 8001
```

**Configuration:**
Edit `backend/mcp_config.json` to set default transport mode and port:
```json
{
  "transport": "stdio",
  "host": "0.0.0.0",
  "port": 8001
}
```

### Available MCP Tools

- **`generate_image`** - Generate images from text prompts with full parameter control
- **`get_model_info`** - Get model status and configuration
- **`update_model_config`** - Modify model settings dynamically
- **Resource: `image://examples`** - Access curated example prompts

### Claude Desktop Integration

Add to your Claude Desktop config file:
```json
{
  "mcpServers": {
    "z-image-turbo": {
      "command": "python",
      "args": ["/path/to/z-image-turbo/backend/mcp_server.py", "--transport", "stdio"]
    }
  }
}
```

ğŸ“– **Full MCP Documentation:** See [`backend/MCP_README.md`](backend/MCP_README.md) for detailed setup, examples, and API reference.

---

## âœ¨ Features

### Application
- **Premium Dark UI** â€” Glassmorphism design with intuitive controls
- **Smart Presets** â€” Quick aspect ratios (1:1, 3:4, 16:9) and resolutions (480p-1080p)
- **Fine Control** â€” Sliders for dimensions, inference steps, guidance scale, and seed
- **Real-time Progress** â€” Live generation tracking
- **Flexible Deployment** â€” Custom model cache directory, CPU offload option

### Model (Z-Image-Turbo)
- **âš¡ Lightning Fast** â€” Optimized for **8-step generation**, achieving sub-second latency on enterprise GPUs.
- **ğŸ—ï¸ S3-DiT Architecture** â€” Built on **Scalable Single-Stream Diffusion Transformer** technology.
- **ğŸ§  Advanced Encoders** â€” Uses **Qwen 4B** for powerful language understanding and **Flux VAE** for image decoding.
- **ğŸ“ DMDR Training** â€” Trained using **Fusing DMD with Reinforcement Learning** for superior semantic alignment.
- **ğŸŒ Bilingual Mastery** â€” Exceptional rendering of text in both **English and Chinese**.
- **ğŸ¨ Versatile & Uncensored** â€” From photorealism to anime, handling complex concepts without censorship.
- **ğŸ“ High Fidelity** â€” Native support for resolutions up to **2MP** (e.g., 1024x1536, 1440x1440).
- **ğŸ’¾ Efficient** â€” 6B parameters, comfortably fitting in 16GB VRAM (consumer-friendly).

---

## ğŸ”¬ Technical Architecture

Z-Image-Turbo represents a significant leap in efficient generative AI:

*   **Base Architecture**: S3-DiT (Scalable Single-Stream DiT)
*   **Text Encoder**: Qwen 4B (Large Language Model based conditioning)
*   **VAE**: Flux Autoencoder
*   **Training Method**: Distilled from Z-Image using DMDR (DMD + RL)
*   **Inference**: 8 NFEs (Number of Function Evaluations) default
*   **Precision**: Optimized for bfloat16 / fp8

---

## ğŸ› ï¸ Tech Stack

- **Backend:** FastAPI, PyTorch, Diffusers, Transformers
- **Frontend:** React, Vite, Lucide React
- **MCP Server:** FastMCP, Starlette (supports stdio and HTTP/SSE transports)
- **Model:** Tongyi-MAI/Z-Image-Turbo (6B parameters)

---

## âš™ï¸ Configuration

Access settings via the gear icon in the sidebar:
- **Model Cache Directory** â€” Specify where to download/store the model
- **CPU Offload** â€” Enable for GPUs with limited VRAM

---

## ğŸ“ License

This project is open-source under the Apache 2.0 License.

---

## ğŸ™ Credits

- **Model:** [Tongyi-MAI/Z-Image-Turbo](https://huggingface.co/Tongyi-MAI/Z-Image-Turbo) by Alibaba Group
- **UI Framework:** React + Vite
- **Backend:** FastAPI + Diffusers

